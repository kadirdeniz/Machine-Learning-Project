{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWu1kVhTINrw"
      },
      "source": [
        "# Traffic Sign Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEa1mAzgISuO"
      },
      "source": [
        "### Model, Loading Data and Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAVkmNVjv_ed"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "EPOCHS = 10\r\n",
        "IMG_WIDTH = 30\r\n",
        "IMG_HEIGHT = 30\r\n",
        "NUM_CATEGORIES = 43\r\n",
        "TEST_SIZE = 0.4\r\n",
        "\r\n",
        "\r\n",
        "def main(path, name = \"trained_model.h5\"):\r\n",
        "\r\n",
        "    # Get image arrays and labels for all image files\r\n",
        "    images, labels = load_data(path)\r\n",
        "\r\n",
        "    # Split data into training and testing sets\r\n",
        "    labels = tf.keras.utils.to_categorical(labels)\r\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\r\n",
        "        np.array(images), np.array(labels), test_size=TEST_SIZE\r\n",
        "    )\r\n",
        "\r\n",
        "    # Get a compiled neural network\r\n",
        "    model = get_model()\r\n",
        "\r\n",
        "    # Fit model on training data\r\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS)\r\n",
        "\r\n",
        "    # Evaluate neural network performance\r\n",
        "    model.evaluate(x_test,  y_test, verbose=2)\r\n",
        "\r\n",
        "    # save the model into the current directory\r\n",
        "    filename = name\r\n",
        "    model.save(filename)\r\n",
        "    print(f\"Model saved to {filename}.\")\r\n",
        "\r\n",
        "\r\n",
        "def load_data(data_dir):\r\n",
        "\r\n",
        "    images = []\r\n",
        "    labels = []\r\n",
        "    \r\n",
        "    for folder in os.listdir(data_dir):\r\n",
        "        if folder == \".DS_Store\": continue\r\n",
        "        else:\r\n",
        "            folder_path = os.path.join(data_dir, folder)\r\n",
        "            for img in os.listdir(folder_path):\r\n",
        "                image_path = os.path.join(folder_path, img)\r\n",
        "                read_img = cv2.imread(image_path)\r\n",
        "                resize_img = cv2.resize(read_img, (IMG_WIDTH, IMG_HEIGHT))\r\n",
        "                images.append(resize_img)\r\n",
        "                labels.append(int(folder))\r\n",
        "\r\n",
        "    return np.array(images), np.array(labels)\r\n",
        "\r\n",
        "def get_model():\r\n",
        "    \r\n",
        "    # input layer of the model\r\n",
        "    input_array = tf.keras.layers.Input(shape = (IMG_WIDTH, IMG_HEIGHT, 3))\r\n",
        "    \r\n",
        "    # first convolution and pooling\r\n",
        "    conv1 = tf.keras.layers.Conv2D(128, (3, 3), (1, 1), \"valid\")(input_array)\r\n",
        "    conv1 = tf.keras.layers.Conv2D(128, (3, 3), (1, 1), \"valid\")(conv1)\r\n",
        "    pool1 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2))(conv1)\r\n",
        "    dropout1 = tf.keras.layers.Dropout(0.2)(pool1)\r\n",
        "\r\n",
        "    # second convolution and pooling\r\n",
        "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), (1, 1), \"valid\")(dropout1)\r\n",
        "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), (1, 1), \"valid\")(conv2)\r\n",
        "    pool2 = tf.keras.layers.MaxPooling2D(pool_size = (1, 1))(conv2)\r\n",
        "    dropout2 = tf.keras.layers.Dropout(0.2)(pool2)\r\n",
        "\r\n",
        "    # third convolution and pooling with batch normalization\r\n",
        "    conv3 = tf.keras.layers.Conv2D(32, (3, 3), (1, 1), \"valid\")(dropout2)\r\n",
        "    conv3 = tf.keras.layers.Conv2D(32, (3, 3), (1, 1), \"valid\")(conv3)\r\n",
        "    pool3 = tf.keras.layers.MaxPooling2D(pool_size = (1, 1))(conv3)\r\n",
        "    dropout3 = tf.keras.layers.Dropout(0.3)(pool3)\r\n",
        "    batch_norm = tf.keras.layers.BatchNormalization()(dropout3)\r\n",
        "\r\n",
        "    # flatten the layers before dense\r\n",
        "    flattened = tf.keras.layers.Flatten()(batch_norm)\r\n",
        "\r\n",
        "    # dense layers for classification \r\n",
        "    dense1 = tf.keras.layers.Dense(128, activation = tf.keras.activations.relu)(flattened)\r\n",
        "    dense2 = tf.keras.layers.Dense(64, activation = tf.keras.activations.relu)(dense1)\r\n",
        "    dense3 = tf.keras.layers.Dense(NUM_CATEGORIES, activation = tf.keras.activations.softmax)(dense2)\r\n",
        "    \r\n",
        "    # final constructed model with type \"tf.keras.models.Model\"\r\n",
        "    model = tf.keras.models.Model(inputs = input_array, outputs = dense3)\r\n",
        "\r\n",
        "    # compiling the model\r\n",
        "    model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 1e-4),\r\n",
        "                  loss = tf.keras.losses.sparse_categorical_crossentropy,\r\n",
        "                  metrics = [\"acc\"])\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldJjnFXZZPSQ"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhSPesy_ZQmu"
      },
      "source": [
        "main(\"gtsrb\", name = \"trained_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnpMetlrZ9aa"
      },
      "source": [
        "### Model Summary\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVMa8T30Z6jw",
        "outputId": "04764876-706d-42a4-a3d3-978c22cedce1"
      },
      "source": [
        "# create model\r\n",
        "model = get_model()\r\n",
        "\r\n",
        "# model summary\r\n",
        "model.summary()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 30, 30, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 28, 28, 128)       3584      \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 26, 26, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 11, 11, 64)        73792     \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 7, 7, 32)          18464     \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 5, 5, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 5, 5, 32)          128       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 400,707\n",
            "Trainable params: 400,643\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}